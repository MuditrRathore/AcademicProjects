{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chart-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Desktop\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "print(os.getcwd())\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#friday_afternoon_ddos = pd.read_csv('C:/Users/hp/Desktop/Thesis/Dataset/Automated-Underwriting-master/Packetdata/Friday-WorkingHours-Afternoon-DDos.csv',low_memory = False)\n",
    "#friday_afternoon_portscan = pd.read_csv('C:/Users/hp/Desktop/Thesis/Dataset/Automated-Underwriting-master/Packetdata/Friday-WorkingHours-Afternoon-PortScan.csv',low_memory = False)\n",
    "#friday_morning = pd.read_csv('C:/Users/hp/Desktop/Thesis/Dataset/Automated-Underwriting-master/Packetdata/Friday-WorkingHours-Morning.csv',low_memory = False)\n",
    "monday = pd.read_csv('C:/Users/hp/Desktop/Thesis/Dataset/Automated-Underwriting-master/Packetdata/Monday-WorkingHours.csv',low_memory = False)\n",
    "#thursday_infilteration = pd.read_csv('C:/Users/hp/Desktop/Thesis/Dataset/Automated-Underwriting-master/Packetdata/Thursday-WorkingHours-Afternoon-Infilteration.csv',low_memory = False)\n",
    "#thursday_webattacks = pd.read_csv('C:/Users/hp/Desktop/Thesis/Dataset/Automated-Underwriting-master/Packetdata/Thursday-WorkingHours-Morning-WebAttacks.csv',low_memory = False)\n",
    "#tuesday = pd.read_csv('C:/Users/hp/Desktop/Thesis/Dataset/Automated-Underwriting-master/Packetdata/Tuesday-WorkingHours.csv',low_memory = False)\n",
    "#wednesday = pd.read_csv('C:/Users/hp/Desktop/Thesis/Dataset/Automated-Underwriting-master/Packetdata/Wednesday-WorkingHours.csv',low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#friday_afternoon_ddos = friday_afternoon_ddos.rename(str.lstrip, axis='columns')\n",
    "#friday_afternoon_portscan = friday_afternoon_portscan.rename(str.lstrip, axis='columns')\n",
    "#friday_morning = friday_morning.rename(str.lstrip, axis='columns')\n",
    "monday = monday.rename(str.lstrip, axis='columns')\n",
    "#thursday_infilteration = thursday_infilteration.rename(str.lstrip, axis='columns')\n",
    "#thursday_webattacks = thursday_webattacks.rename(str.lstrip, axis='columns')\n",
    "#tuesday = tuesday.rename(str.lstrip, axis='columns')\n",
    "#wednesday = wednesday.rename(str.lstrip, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BENIGN']\n",
      "(529918, 79)\n"
     ]
    }
   ],
   "source": [
    "df = monday\n",
    "print(df['Label'].unique())\n",
    "number = LabelEncoder()\n",
    "df[\"Label\"] = number.fit_transform(df[\"Label\"])\n",
    "print(df.shape)\n",
    "#print(df.isnull().sum())\n",
    "#print(df.select_dtypes(include=['float64']))\n",
    "df = df.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != \"Label\"].values\n",
    "y = df.loc[:, df.columns == \"Label\"].values.flatten()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=123,stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimportances = rf_clf.feature_importances_\\nindices = np.argsort(rf_clf.feature_importances_)[::-1]\\npos = np.arange(len(importances))\\ndata = [go.Bar(x = pos, y=importances)]\\npy.iplot(data, filename=\\'basic-bar\\')\\n\\nplt.figure(figsize=(12, 6))\\nplt.bar(pos, importances[indices], align=\"center\")\\nplt.xticks(range(1,100),\\n           df.columns[df.columns != \"Label\"][indices],\\n           rotation=90)\\nplt.title(\"Feature Importance\", {\"fontsize\": 16});\\nplt.show()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "importances = rf_clf.feature_importances_\n",
    "indices = np.argsort(rf_clf.feature_importances_)[::-1]\n",
    "pos = np.arange(len(importances))\n",
    "data = [go.Bar(x = pos, y=importances)]\n",
    "py.iplot(data, filename='basic-bar')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(pos, importances[indices], align=\"center\")\n",
    "plt.xticks(range(1,100),\n",
    "           df.columns[df.columns != \"Label\"][indices],\n",
    "           rotation=90)\n",
    "plt.title(\"Feature Importance\", {\"fontsize\": 16});\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = RobustScaler()\n",
    "std.fit(X_train)\n",
    "X_train = std.transform(X_train)\n",
    "X_test = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg_clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial',n_jobs = 3)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, max_features=0.25, criterion=\"entropy\", class_weight=\"balanced\")\n",
    "\n",
    "#mathdomainerror still\n",
    "#pca_clf = PCA(n_components='mle')\n",
    "\n",
    "#ann_clf = MLPClassifier(activation = 'logistic')\n",
    "\n",
    "lda_clf = LinearDiscriminantAnalysis(solver='svd')\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "dtree_clf = DecisionTreeClassifier()\n",
    "\n",
    "#list of predicted labels in the above given order\n",
    "predicted_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this\n",
    "logreg_clf.fit(X_train,y_train)\n",
    "predicted_labels_logreg = logreg_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predicted_labels_logreg))\n",
    "#predicted_labels.append(predicted_labels_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this\n",
    "rf_clf.fit(X_train,y_train)\n",
    "predicted_labels_rf = rf_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predicted_labels_rf))\n",
    "#predicted_labels.append(predicted_labels_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this\n",
    "ann_clf.fit(X_train,y_train)\n",
    "predicted_labels_ann = ann_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predicted_labels_ann))\n",
    "#predicted_labels.append(predicted_labels_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning:\n",
      "\n",
      "Variables are collinear.\n",
      "\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:402: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#change this\n",
    "lda_clf.fit(X_train,y_train)\n",
    "predicted_labels_lda = lda_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predicted_labels_lda))\n",
    "#predicted_labels.append(predicted_labels_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#change this\n",
    "knn_clf.fit(X_train,y_train)\n",
    "predicted_labels_knn = knn_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predicted_labels_knn))\n",
    "#predicted_labels.append(predicted_labels_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#change this\n",
    "nb_clf.fit(X_train,y_train)\n",
    "predicted_labels_nb = nb_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predicted_labels_nb))\n",
    "#predicted_labels.append(predicted_labels_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#change this\n",
    "dtree_clf.fit(X_train,y_train)\n",
    "predicted_labels_dtree = dtree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predicted_labels_dtree))\n",
    "#predicted_labels.append(predicted_labels_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models ={\"logreg\": logreg_clf,      \n",
    "         \"rf\": rf_clf,\n",
    "         \"ann\": ann_clf,\n",
    "         \"lda\": lda_clf,\n",
    "         \"knn\": knn_clf,\n",
    "         \"nb\": nb_clf,\n",
    "         \"dtree\": dtree_clf\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "temp = []\n",
    "for i in range(len(models)):\n",
    "    temp.append(i+1)\n",
    "for (name, model, i) in zip(models.keys(), models.values(), temp):\n",
    "    print(name, model, i)\n",
    "    \n",
    "print()\n",
    "print()\n",
    "for i in predicted_labels:\n",
    "    print(i)\n",
    "    \n",
    "\"\"\"\n",
    "type(predicted_labels_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "i = 1\n",
    "cm =[]\n",
    "cm1 = confusion_matrix(y_test,predicted_labels_logreg)\n",
    "print(\"Confusion Matrix for logreg \\n\", cm1)\n",
    "cm.append(cm1)\n",
    "cm2 = confusion_matrix(y_test,predicted_labels_rf)\n",
    "print(\"Confusion Matrix for rf\\n\", cm2)\n",
    "cm.append(cm2)\n",
    "cm3 = confusion_matrix(y_test,predicted_labels_ann)\n",
    "print(\"Confusion Matrix for ann\\n\", cm3)\n",
    "cm.append(cm3)\n",
    "cm4 = confusion_matrix(y_test,predicted_labels_lda)\n",
    "print(\"Confusion Matrix for lda \\n\", cm4)\n",
    "cm.append(cm4)\n",
    "cm5 = confusion_matrix(y_test,predicted_labels_knn)\n",
    "print(\"Confusion Matrix for knn\\n\", cm5)\n",
    "cm.append(cm5)\n",
    "cm6 = confusion_matrix(y_test,predicted_labels_nb)\n",
    "print(\"Confusion Matrix for nb\\n\", cm6)\n",
    "cm.append(cm6)\n",
    "cm7 = confusion_matrix(y_test,predicted_labels_dtree)\n",
    "print(\"Confusion Matrix \\n\", cm7)\n",
    "cm.append(cm7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#metalearner 1 boosting\n",
    "xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                            learning_rate=0.03,\n",
    "                            n_estimators=500,\n",
    "                            max_depth=1,\n",
    "                            subsample=0.4,\n",
    "                            random_state=123)\n",
    "\"\"\"\n",
    "#metalearner 2 averaging\n",
    "voting_clf = VotingClassifier([(\"logreg\", logreg_clf),\n",
    "                               (\"rf\", rf_clf)],\n",
    "                              voting=\"soft\",\n",
    "                              flatten_transform=True)\n",
    "print(\"check1\")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"check2\")\n",
    "logreg_model, rf_model = voting_clf.estimators_\n",
    "print(\"check3\")\n",
    "models = {\"logreg\": logreg_model,\n",
    "          \"rf\": rf_model,\n",
    "\"avg_ensemble\": voting_clf}\n",
    "\n",
    "print(\"check4\")\n",
    "first_stack = make_pipeline(voting_clf,\n",
    "                            FunctionTransformer(lambda X: X[:, 1::2]))\n",
    "\n",
    "print(\"check5\")\n",
    "# Use CV to generate meta-features\n",
    "\n",
    "\"\"\"\n",
    "meta_features = cross_val_predict(first_stack, X_train, y_train, cv=10, method=\"transform\")\n",
    "\n",
    "\n",
    "# Refit the first stack on the full training set\n",
    "first_stack.fit(X_train, y_train)\n",
    "\n",
    "print(\"check6\")\n",
    "\n",
    "# Fit the meta learner\n",
    "#second_stack = xgb_clf.fit(meta_features, y_train)\n",
    "test_meta = cross_val_predict(first_stack, X_test, y_test, cv=10, method=\"transform\")\n",
    "#acc = accuracy_score(y_test,second_stack.predict(test_meta))\n",
    "#print(\"Accuracy score using stacking ensemble model\", acc)\n",
    "acc2 = accuracy_score(y_test,voting_clf.predict(X_test))\n",
    "print(\"Accuracy score using averaging ensemble model\", acc2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2 = accuracy_score(y_test,voting_clf.predict(X_test))\n",
    "print(\"Accuracy score using averaging ensemble model\", acc2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
