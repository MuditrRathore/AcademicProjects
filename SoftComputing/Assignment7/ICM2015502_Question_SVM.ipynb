{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport random as rnd\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/mnist_test.csv', dtype=\"int32\")\n#y_df = pd.read_csv('../input/mnist_train.csv', header = None)\ny = df['label']\nx = df.drop('label', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = y.values\nx = x.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_x = []\ndata_y = []\nfor index, label in enumerate(y):\n    if(label == 3 or label == 8):\n        data_x.append(x[index])\n        if(label == 3):\n          data_y.append(1)\n        else:\n          data_y.append(-1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_x = np.asarray(data_x)\ndata_y = np.asarray(data_y)\nprint(\"shape of x: \"+ str(data_x.shape), \"shape of y: \"+str(data_y.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = tts(data_x, data_y, test_size = 0.4, random_state = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SVM():\n    def __init__(self, max_iter=100, kernel_type='linear', C=1.0, epsilon=0.001):\n        self.kernels = {\n            'linear' : self.kernel_linear,\n            'quadratic' : self.kernel_quadratic,\n            'gaussian' : self.kernel_gauss\n        }\n        self.max_iter = max_iter\n        self.kernel_type = kernel_type\n        self.C = C\n        self.epsilon = epsilon\n    def fit(self, X, y):\n        n, d = X.shape[0], X.shape[1]\n        alpha = np.zeros((n))\n        kernel = self.kernels[self.kernel_type]\n        count = 0\n        while True:\n            count += 1\n            alpha_prev = np.copy(alpha)\n            for j in range(0, n):\n                i = self.get_rnd_int(0, n-1, j) # Get random int i~=j\n                x_i, x_j, y_i, y_j = X[i,:], X[j,:], y[i], y[j]\n                k_ij = kernel(x_i, x_i) + kernel(x_j, x_j) - 2 * kernel(x_i, x_j)\n                if k_ij == 0:\n                    continue\n                alpha_prime_j, alpha_prime_i = alpha[j], alpha[i]\n                (L, H) = self.compute_L_H(self.C, alpha_prime_j, alpha_prime_i, y_j, y_i)\n\n                # Compute model parameters\n                self.w = self.calc_w(alpha, y, X)\n                self.b = self.calc_b(X, y, self.w)\n\n                # Compute E_i, E_j\n                E_i = self.E(x_i, y_i, self.w, self.b)\n                E_j = self.E(x_j, y_j, self.w, self.b)\n\n                # Set new alpha values\n                alpha[j] = alpha_prime_j + float(y_j * (E_i - E_j))/k_ij\n                alpha[j] = max(alpha[j], L)\n                alpha[j] = min(alpha[j], H)\n\n                alpha[i] = alpha_prime_i + y_i*y_j * (alpha_prime_j - alpha[j])\n                if(j % 100 == 0):\n                    print(j)\n            # Check convergence\n            diff = np.linalg.norm(alpha - alpha_prev)\n            if diff < self.epsilon:\n                break\n            #print(count)\n            if count >= self.max_iter:\n                print(\"Iteration number exceeded the max of %d iterations\" % (self.max_iter))\n                return\n        self.b = self.calc_b(X, y, self.w)\n        if self.kernel_type == 'linear':\n            self.w = self.calc_w(alpha, y, X)\n        # Get support vectors\n        alpha_idx = np.where(alpha > 0)[0]\n        support_vectors = X[alpha_idx, :]\n        return support_vectors, count\n    def predict(self, X):\n        return self.h(X, self.w, self.b)\n    def calc_b(self, X, y, w):\n        b_tmp = y - np.dot(w.T, X.T)\n        return np.mean(b_tmp)\n    def calc_w(self, alpha, y, X):\n        return np.dot(X.T, np.multiply(alpha,y))\n    def h(self, X, w, b):\n        return np.sign(np.dot(w.T, X.T) + b).astype(int)\n    def E(self, x_k, y_k, w, b):\n        return self.h(x_k, w, b) - y_k\n    def compute_L_H(self, C, alpha_prime_j, alpha_prime_i, y_j, y_i):\n        if(y_i != y_j):\n            return (max(0, alpha_prime_j - alpha_prime_i), min(C, C - alpha_prime_i + alpha_prime_j))\n        else:\n            return (max(0, alpha_prime_i + alpha_prime_j - C), min(C, alpha_prime_i + alpha_prime_j))\n    def get_rnd_int(self, a,b,z):\n        i = z\n        cnt=0\n        while i == z and cnt<1000:\n            i = rnd.randint(a,b)\n            cnt=cnt+1\n        return i\n    def kernel_linear(self, x1, x2):\n        return np.dot(x1, x2.T)\n    def kernel_quadratic(self, x1, x2):\n        return (np.dot(x1, x2.T) ** 2)\n    def kernel_gauss(self,x1, x2, sigma=1):\n        return np.exp(- (np.linalg.norm(x1 - x2, 2)) ** 2 / (2 * sigma ** 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SVM(max_iter=3, kernel_type='linear', C=1.0, epsilon=0.001)\nmodel.fit(X_train, Y_train)\nY_predicted = [model.predict(x) for x in X_test]\ncm = confusion_matrix(Y_test, Y_predicted)\naccuracy = (cm[0][0] + cm[1][1]) / (cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SVM(max_iter=3, kernel_type='gaussian', C=1.0, epsilon=0.001)\nmodel.fit(X_train, Y_train)\nY_predicted = [model.predict(x) for x in X_test]\ncm = confusion_matrix(Y_test, Y_predicted)\naccuracy = (cm[0][0] + cm[1][1]) / (cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SVM(max_iter=3, kernel_type='quadratic', C=1.0, epsilon=0.001)\nmodel.fit(X_train, Y_train)\nY_predicted = [model.predict(x) for x in X_test]\ncm = confusion_matrix(Y_test, Y_predicted)\naccuracy = (cm[0][0] + cm[1][1]) / (cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])\nprint(accuracy)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}